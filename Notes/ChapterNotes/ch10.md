# Chapter 10, Efficient MPI programming
Performance problems in a parallelized program are related to well-known general issues such as
* Serial execution (Amdahl's Law)
* Load imbalance
* Unnecessary synchronization
* Other effects that impact all parallel programming models

Specific MPI problems:
* Unjustified assumptions about distributed-memory parallelization
* Over-optimistic notions regarding the cost and side effects of communication
* Platform portability

This chapter: sketch the most relevant guidelines for efficient MPI programming.

## 10.1 MPI performance tools
The root cause is hard to find in an MPI program.
**IPM** is a simple and low-overhead tool that retrieves information such as time spent in the MPI library and application code, dominating functions etc.

More advanced profiling tools (such as Intel Trace Analyzer) can show for example *Event timeline* in a GUI.

## 10.2 Communication parameters
MPI message transfers are complex.
* Short messages: the message itself w/supplementary information may be sent and stored at the receivers side. At some point the intermediate buffer will be copied to the receiver buffer: *eager protocol*. Too many of these protocols may cause contention or program crashes.
* Large messages: envelope is immediately stored at the receiver, but the actual message transfer blocks until the user's receive buffer is available. Extra data copies could be avoided, improving effective bandwidth, but sender and receiver must synchronize. This is called the *rendezvous protocol*.

It could be useful to adjust message length:
`MPI_Issend()` is useful if *eager overflow* could be a problem.

## 10.3 Synchronization, serialization, contention
Performance problems that are not specific to message-passing.
### Implicit serialization and synchronization
Unintended frequent synchronization. Ring shift communication (rank 0->1->2->...->0): if this is periodic, there is a danger of deadlock. If blocking send/recv are used, the communication will take long time. SOLUTION:
* Have all odd/even send and all even/odd recv, then opposite.
* Use nonblocking functions.
* Use blocking point-to-point functions: notably MPI_Sendrecv() or MPI_Sendrecv_replace().
### Contention
Contention to network connections: shared resources within a shared-memory multisocket multicore system. Network contentions occurs on two levels:
* Multiple threads/processes may issue requests to other nodes. If bandwidth dies not scale to multiple connections: the bandwidth per connection will go down. (A single thread can saturate the network interface).
* The network topology may not be fully nonblocking.

Contention of some kind is hardly avoidable in parallel systems if message passing is used.

## 10.4 Reducing communication overhead
### Optimal domain decomposition
Halo communication should be efficient: minimize communicated data volume.
#### Minimizing interdomain surface area
Consider a cube domain of size $L^3$ and let there be $N$ sub-domains. The data volume is of $w$ bytes.
* Slabs (decomposed in one dimension): $2wL^2$
* Poles (decomposed in two dimensions): $4wL^2 N^{-1/2}$. ($N>4$ to beat slabs)
* Cubes (decomposed in three dimensions): $6wL^2N^{-2/3}.
#### Mapping issues
Modern parallel computers are of the hierarchical type. 'MPI_Cart_create()' can optimize mapping.
### Aggregating messages
Small messages should be aggregated into contiguous buffers and sent in larger chunk so that the latency penalty must only be paid once.
#### Message aggregation and derived datatypes
A typical case for message aggregation comes up when separate, i.e., noncontigu-
ous data items must be transferred between processes.

MPI provides derived datatypes, which support this functionality, and it is possible for the programmer to introduce new data types: must be names MPI_Type_xxxxx().

Even if aggregation takes place, one cannot be sure whether it
is done in the most efficient way; e.g., nontemporal stores could be beneficial for
large data volume, or (if multiple threads per MPI process are available) copying
could be multithreaded. In general, if communication of derived datatypes is crucial
for performance, one should not rely on the libraryâ€™s efficiency but check whether
manual copying improves performance.

### Nonblocking vs. asynchronous communication
Reducing the communication overhead is good, but what else can be done?
* Overlapping communication and computation. (Non-blocking point-to-point seems to be the solution here).
NB: one must strictly differentiate between nonblocking and *truly* asynchronous communication. What is the difference?
* Nonblocking, merely implies that the buffer cannot be used after the call has returned from the MPI library.

This subchapter says alot about how truly asynchronous communication is hard to achieve and has very little support and only works on a few systems. The lesson is that one should not put too much optimization effort into utilizing
asynchronous communication by means of nonblocking point-to-point calls, because
it will only pay off in very few environments.

However, nonblocking MPI is of much use:
1. reduce idle times,
2. prevent deadlocks,
3. handling multiple outstanding communication requests efficiently.


### Collective communication
Collective communication (i.e. MPI_Reduce) can make multiple calls in to a single call, this reduces programming complexity, but it has an additional potential:
* there are inbuilt algorithms to achieve reasonable performance on any network. In the ideal case, the library has knowledge about the network topology.


## 10.5 Understanding intranode point-to-point communication
What is the most optimal distribution of threads and processes across the cores and nodes? We must remember that there is a bandwidth (information flux, around a few GBytes/sec). Some things to think about:
* Nontemporal stores or cache line zeros may be used or not.
* Data transfer may be single-copy.
* There may be hardware support for intranode memory-to-memory transfers.

Two cores on the same socket can really benefit from the shared L3 cache. It all depends on the message size.

There is a very technical example in this subchapter, but probably not necessary.
